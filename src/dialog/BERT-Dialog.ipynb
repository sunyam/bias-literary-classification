{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31175,
     "status": "ok",
     "timestamp": 1599672454213,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "XNevBdUGoyGJ",
    "outputId": "0bf297c6-2780-48f1-c075-5f8a7ff30deb"
   },
   "source": [
    "### BERT for Dialog experiments\n",
    "- We used Google Colaboratory for free GPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1599673503639,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "4E-MqoeQppFW",
    "outputId": "73658649-4591-4d4a-d77d-6255a3cd77b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'dialog-mys-data-booknlp-output', 'dialog-non-data-booknlp-output']"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_PATH = '/content/gdrive/My Drive/txtLAB-2020/bert-dialog/'\n",
    "import os\n",
    "os.listdir(HOME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2352,
     "status": "ok",
     "timestamp": 1599673507559,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "NxriYi8Zr5DW"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "DATA_PATH = HOME_PATH + 'data/'\n",
    "FIC_BOOKNLP_PATH = HOME_PATH + 'dialog-mys-data-booknlp-output/'\n",
    "NON_BOOKNLP_PATH = HOME_PATH + 'dialog-non-data-booknlp-output/'\n",
    "\n",
    "\n",
    "def get_passage(df, start, N=500):\n",
    "    \"\"\"\n",
    "    Given the of the BookNLP output DataFrame & index of the starting word (start), this function \n",
    "    returns a 500-word passage starting at index 'start'. Also returns % of words in dialogue.\n",
    "    \"\"\"\n",
    "    id_list = list((range(start, start+N)))\n",
    "#     print(\"Get 500 words from index {} to {}\".format(id_list[0], id_list[-1]))\n",
    "    df = df.loc[df['tokenId'].isin(id_list)]\n",
    "    words = df['originalWord'].tolist()\n",
    "    # if len(words) != N:\n",
    "    #     print(\"Word-count is:\", len(words))\n",
    "    \n",
    "    quoted_words = df.loc[df['inQuotation']=='I-QUOTE']['originalWord'].tolist() # filter again incase BookNLP missed any\n",
    "#     print(\"Quoted:\", len(quoted_words), quoted_words[:4])\n",
    "    return ' '.join(words), len(quoted_words)\n",
    "    \n",
    "    \n",
    "def sample_random_text(fname, two_passages=False):\n",
    "    \"\"\"\n",
    "    Returns a random 500-word passage from the middle of the given volume (used for non-fiction).\n",
    "    \"\"\"\n",
    "    N_WORDS = 500; pct = 0.3\n",
    "    df = pd.read_csv(fname, delimiter='\\t', quoting=csv.QUOTE_NONE) # no quotechar\n",
    "    df.dropna(subset=['originalWord'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    total_words = df.shape[0]\n",
    "    first = int(pct*total_words)\n",
    "    last = int(total_words - pct*total_words)\n",
    "    \n",
    "    if two_passages:\n",
    "#         print(\"Sample 2 random passages from\", fname)\n",
    "        start_index = first\n",
    "        text1, _ = get_passage(df, start_index)\n",
    "        text2, _ = get_passage(df, start_index+N_WORDS)\n",
    "        return [text1, text2]\n",
    "        \n",
    "    else:\n",
    "#         print(\"Sample 1 passage from\", fname)\n",
    "        start_index = first\n",
    "        text, _ = get_passage(df, start_index)\n",
    "        return text\n",
    "    \n",
    "\n",
    "def sample_texts(fname, dialog=True):\n",
    "    \"\"\"\n",
    "    If dialog is False, returns two 500-word passages with zero dialogue.\n",
    "    \n",
    "    If dialog is True, samples all possible 500 word passages from the given novel (30% text from either side is skipped)\n",
    "    And returns the top two samples with most dialogue along with the % dialog in those two texts.\n",
    "    \"\"\"\n",
    "    N_WORDS = 500; pct = 0.3\n",
    "    df = pd.read_csv(fname, delimiter='\\t', quoting=csv.QUOTE_NONE) # no quotechar\n",
    "    df.dropna(subset=['originalWord'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    total_words = df.shape[0]\n",
    "    inside_quotes = df['inQuotation'].value_counts().to_dict()[\"I-QUOTE\"]\n",
    "    first = int(pct*total_words)\n",
    "    last = int(total_words - pct*total_words)\n",
    "    \n",
    "#     print(\"Total words in the volume: {} | Words inside quotes (BookNLP): {}\".format(total_words, inside_quotes))\n",
    "#     print(\"Sample random passages from word index {} to {}\".format(first, last))\n",
    "\n",
    "    map_i_tup = {} # maps run number 'i' to a tuple of (quoted words & corresponding text)\n",
    "    non_dialog_texts = []\n",
    "    start_index = first\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        if start_index + N_WORDS >= last:\n",
    "            break\n",
    "            \n",
    "        text, quoted = get_passage(df, start_index)\n",
    "        start_index += N_WORDS\n",
    "        \n",
    "        if len(non_dialog_texts) < 2 and quoted == 0:\n",
    "            non_dialog_texts.append(text)\n",
    "            \n",
    "        map_i_tup[i] = (quoted, text)\n",
    "        i += 1\n",
    "        \n",
    "    if not dialog:\n",
    "        return non_dialog_texts\n",
    "        \n",
    "    if dialog:\n",
    "        sorted_keys = sorted(map_i_tup, key=lambda k: map_i_tup[k][0])\n",
    "        dialog_texts, pct_quoted = [], []\n",
    "        for key in sorted_keys[-2:]:\n",
    "            if map_i_tup[key][0] == 0: # did not have quoted words, return -1\n",
    "#                print(\"OOOOPS::::: ID number:\", key, \"has quoted words:\", map_i_tup[key][0])                \n",
    "                return -1\n",
    "\n",
    "#             print(\"ID number:\", key, \"has quoted words:\", map_i_tup[key][0])\n",
    "            dialog_texts.append(map_i_tup[key][1])\n",
    "            pct_quoted.append(map_i_tup[key][0]/N_WORDS)\n",
    "\n",
    "        return dialog_texts, pct_quoted\n",
    "\n",
    "    \n",
    "#### Train-Data ####\n",
    "\n",
    "def load_train_fnames():\n",
    "    \"\"\"\n",
    "    Returns a list of filenames to be used for train-data.\n",
    "    \"\"\"\n",
    "    fiction_fnames = [DATA_PATH+'Train/NovelEnglish_Mystery/'+fname for fname in os.listdir(DATA_PATH+'Train/NovelEnglish_Mystery/')]\n",
    "    non_fiction_fnames = [DATA_PATH+'Train/NonNovel_English_Contemporary_Mixed/'+fname for fname in os.listdir(DATA_PATH+'Train/NonNovel_English_Contemporary_Mixed/')]\n",
    "    print(\"Train Fiction fnames:\", len(fiction_fnames), \"| Train Non-Fiction fnames:\", len(non_fiction_fnames))\n",
    "    return fiction_fnames, non_fiction_fnames\n",
    "\n",
    "\n",
    "def load_train_data(dial, no_dial, return_ids=True, N_WORDS=500):\n",
    "    \"\"\"\n",
    "    Returns X and Y for training (len=400), given the experiment and the scenario. Also returns the IDs if flag is set to True.\n",
    "    Training = 200 fic / 200 nonfic \n",
    "    \n",
    "    The 200 fiction volumes has dialogue/no-dialogue distributions as specified by 'dial' & 'no_dial'.\n",
    "    dial represents the percent of the fiction-train-set that should have dialog and no_dial represents without-dialog.\n",
    "    They should add up to 1.\n",
    "    \n",
    "    The 200 nonfic has random 500-word passasges from the non-fiction volumes.\n",
    "    \n",
    "    2 passages per volume.\n",
    "    \"\"\"\n",
    "    fiction_fnames, non_fiction_fnames = load_train_fnames()\n",
    "    assert len(fiction_fnames) > len(non_fiction_fnames) == 100\n",
    "    \n",
    "    assert dial + no_dial == 1\n",
    "    \n",
    "    X, Y, IDs = [], [], [] # corresponding list of texts, labels, and unique IDs\n",
    "\n",
    "    with_dial, without_dial = 0, 0 # counters\n",
    "    pct_quoted_fic = [] # keep track of how much \"dialog\" we have in our dialog data\n",
    "    \n",
    "    for fname in fiction_fnames:\n",
    "        if with_dial == dial*200 and without_dial == no_dial*200:\n",
    "            break\n",
    "        \n",
    "        fname = FIC_BOOKNLP_PATH + fname.split('/')[-1] + '/' + fname.split('/')[-1]\n",
    "        if not os.path.isfile(fname+'.tokens'):\n",
    "            print(fname, \"doesn't exist. Skip!\")\n",
    "            continue\n",
    "        \n",
    "        if without_dial < no_dial*200: # look for passages without-dialog\n",
    "            try:\n",
    "                ret = sample_texts(fname+'.tokens', dialog=False)\n",
    "                assert len(ret) == 2\n",
    "                X.extend(ret)\n",
    "                without_dial += 2\n",
    "                IDs.append(\"ficNoDialog1____\" + fname.split('/')[-1])\n",
    "                IDs.append(\"ficNoDialog2____\" + fname.split('/')[-1])\n",
    "            except:\n",
    "                if with_dial >= dial*200:\n",
    "#                    print(\"Have already reached the limit for with-dialogs: {} {}\\tSkip!\".format(with_dial, dial*200))\n",
    "                    continue\n",
    "#                print(\"Could not find zero-dialog passages in {} | Try for with-dialogue..\".format(fname.split('/')[-1]))\n",
    "                ret = sample_texts(fname+'.tokens', dialog=True)\n",
    "                if ret == -1:\n",
    "                    print(\"Returned -1. Skip!\")\n",
    "                    continue\n",
    "                X.append(ret[0][0])\n",
    "                X.append(ret[0][1])\n",
    "                pct_quoted_fic.append(ret[1][0])\n",
    "                pct_quoted_fic.append(ret[1][1])\n",
    "                with_dial += 2\n",
    "                IDs.append(\"ficWithDialog1____\" + fname.split('/')[-1])\n",
    "                IDs.append(\"ficWithDialog2____\" + fname.split('/')[-1])\n",
    "        \n",
    "        elif with_dial < dial*200: # look for passages with-dialog\n",
    "            ret = sample_texts(fname+'.tokens', dialog=True)\n",
    "            try:\n",
    "                X.append(ret[0][0])\n",
    "                X.append(ret[0][1])\n",
    "                pct_quoted_fic.append(ret[1][0])\n",
    "                pct_quoted_fic.append(ret[1][1])\n",
    "                with_dial += 2\n",
    "                IDs.append(\"ficWithDialog1____\" + fname.split('/')[-1])\n",
    "                IDs.append(\"ficWithDialog2____\" + fname.split('/')[-1])\n",
    "            except:\n",
    "                print(fname, \"does not have quoted words.. Skip!\")\n",
    "                continue\n",
    "                \n",
    "        Y.append(\"fic\")\n",
    "        Y.append(\"fic\")\n",
    "#        print(\"With dial: {} | Without dial: {} | Pct quoted: {} | Y: {} | X: {}\".format(with_dial, without_dial, len(pct_quoted_fic), len(Y), len(X))) \n",
    "#    print(\"End of fiction-fnames! X: {} | Y: {}\".format(len(X), len(Y)))\n",
    "\n",
    "    for fname in non_fiction_fnames: # all random\n",
    "        IDs.append(\"non1____\" + fname.split('/')[-1])\n",
    "        IDs.append(\"non2____\" + fname.split('/')[-1])\n",
    "        fname = NON_BOOKNLP_PATH + fname.split('/')[-1] + '/' + fname.split('/')[-1] + '.tokens'\n",
    "        X.extend(sample_random_text(fname, two_passages=True))\n",
    "        Y.extend([\"non\", \"non\"])\n",
    "    \n",
    "    assert with_dial == dial*200 == len(pct_quoted_fic)\n",
    "    assert without_dial == no_dial*200\n",
    "    assert len(X) == len(Y) == len(IDs) == 400\n",
    "    \n",
    "    if return_ids:\n",
    "        return np.array(X), np.array(Y), np.array(pct_quoted_fic), np.array(IDs)\n",
    "    else:\n",
    "        return np.array(X), np.array(Y), np.array(pct_quoted_fic)\n",
    "    \n",
    "    \n",
    "#### Test-Data ####\n",
    "\n",
    "def load_test_fnames():\n",
    "    \"\"\"\n",
    "    Returns a list of filenames to be used as test-data.\n",
    "    Test Data for all cases: 200 docs (100 \"Non\" & 100 fiction: 50 \"with dialog\" + 50 \"without dialog\")\n",
    "    \"\"\"\n",
    "    test_path = DATA_PATH + 'Test/'\n",
    "    fiction_fnames = [test_path+'NovelEnglish_Mystery/'+fname for fname in os.listdir(test_path+'NovelEnglish_Mystery/')]\n",
    "    non_fiction_fnames = [test_path+'NonNovel_English_Contemporary_Mixed/'+fname for fname in os.listdir(test_path+'NonNovel_English_Contemporary_Mixed/')]\n",
    "    print(\"Test Fiction fnames:\", len(fiction_fnames), \"| Test Non-Fiction fnames:\", len(non_fiction_fnames))\n",
    "    \n",
    "    return fiction_fnames, non_fiction_fnames\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Returns X and Y for test set. Also returns a corresponding list of IDs.\n",
    "    100 random non-fiction passages + 50 fiction passages with-dialog + 50 fiction passages without-dialog\n",
    "    \n",
    "    Each passage is contiguous 500-words from the volume. Uses one passage per volume.\n",
    "    \"\"\"\n",
    "    fiction_fnames, non_fiction_fnames = load_test_fnames()\n",
    "\n",
    "    assert len(fiction_fnames) == len(non_fiction_fnames) == 100\n",
    "    \n",
    "    X, Y, IDs = [], [], [] # corresponding list of texts, labels, and unique IDs\n",
    "\n",
    "    with_dial, without_dial = 0, 0\n",
    "    pct_quoted_fic = []\n",
    "    \n",
    "    for fname in fiction_fnames:\n",
    "        fname = FIC_BOOKNLP_PATH + fname.split('/')[-1] + '/' + fname.split('/')[-1]\n",
    "\n",
    "        if without_dial < 50:\n",
    "            try:\n",
    "                X.append(sample_texts(fname+'.tokens', dialog=False)[0])\n",
    "                without_dial += 1\n",
    "                IDs.append(\"ficNoDialog____\" + fname.split('/')[-1])\n",
    "            except:\n",
    "#                print(\"Could not find zero-dialog passages in {} | Try for with-dialogue..\".format(fname.split('/')[-1]))\n",
    "                ret = sample_texts(fname+'.tokens', dialog=True)\n",
    "                X.append(ret[0][1])\n",
    "                pct_quoted_fic.append(ret[1][1])\n",
    "                with_dial += 1\n",
    "                IDs.append(\"ficWithDialog____\" + fname.split('/')[-1])\n",
    "        \n",
    "        else:\n",
    "            ret = sample_texts(fname+'.tokens', dialog=True)\n",
    "            try:\n",
    "                X.append(ret[0][1])\n",
    "                pct_quoted_fic.append(ret[1][1])\n",
    "                with_dial += 1\n",
    "                IDs.append(\"ficWithDialog____\" + fname.split('/')[-1])\n",
    "            except:\n",
    "#                print(fname, \"does not have quoted words. Skip!\")\n",
    "                continue\n",
    "                \n",
    "        Y.append(\"fic\")\n",
    "#        print(\"With dial: {} | Without dial: {} | Pct quoted: {} | Y: {}\".format(with_dial, without_dial, len(pct_quoted_fic), len(Y))) \n",
    "        if with_dial == without_dial == 50:\n",
    "            break\n",
    "\n",
    "    for fname in non_fiction_fnames: # random passages\n",
    "        IDs.append(\"non____\" + fname.split('/')[-1])\n",
    "        fname = NON_BOOKNLP_PATH + fname.split('/')[-1] + '/' + fname.split('/')[-1] + '.tokens'\n",
    "        X.append(sample_random_text(fname))\n",
    "        Y.append(\"non\")\n",
    "\n",
    "    assert with_dial == without_dial == len(pct_quoted_fic) == 50\n",
    "    assert len(X) == len(Y) == len(IDs) == 200\n",
    "    return np.array(X), np.array(Y), np.array(pct_quoted_fic), np.array(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4153,
     "status": "ok",
     "timestamp": 1599673511342,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "ETjSY0e_r5yK",
    "outputId": "61d99ea9-1b7b-445c-96f5-dc297e7f76dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Inspired from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "import torch\n",
    "import random, time, datetime\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def prepare_dataloader(texts, labels, IDs=[], batch_size=8, max_length=512):\n",
    "    \"\"\"\n",
    "    Takes as input: texts, labels, and corresponding IDs (in case of test-data)\n",
    "    This function returns a DataLoader object.\n",
    "\n",
    "    For train_dataloader, labels are passed. For test_dataloader, both labels and IDs are passed.\n",
    "    BERT tokenizer is used to\n",
    "      (1) Tokenize the sentence.\n",
    "      (2) Prepend the `[CLS]` token to the start.\n",
    "      (3) Append the `[SEP]` token to the end.\n",
    "      (4) Map tokens to their IDs.\n",
    "      (5) Pad or truncate the sentence to `max_length`\n",
    "      (6) Create attention masks for [PAD] tokens.\n",
    "    Authors recommend a batch size of 16/32 for fine-tuning.\n",
    "    \"\"\"\n",
    "    input_ids = []; attention_masks = []\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    for sent in texts:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, # sentence to encode\n",
    "                                             add_special_tokens=True, # add '[CLS]' and '[SEP]'\n",
    "                                             truncation=True,\n",
    "                                             max_length=512,\n",
    "                                             pad_to_max_length=True,\n",
    "                                             return_attention_mask=True, # construct attention masks\n",
    "                                             return_tensors='pt') # return pytorch tensorss\n",
    "\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask']) # simply differentiates padding from non-padding\n",
    "\n",
    "    # Convert to tensors:\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if IDs == []: # for training data\n",
    "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "        print(\"Dataset has input_ids, attention_masks, labels | Length:\", len(dataset))\n",
    "        \n",
    "    else: # for test data\n",
    "        IDs = torch.tensor(IDs)\n",
    "        print(\"Dataset has input_ids, attention_masks, labels, and IDs\")\n",
    "        dataset = TensorDataset(input_ids, attention_masks, labels, IDs)\n",
    "        assert len(dataset) == 200\n",
    "\n",
    "    data_loader = DataLoader(dataset,\n",
    "                             sampler=RandomSampler(dataset),\n",
    "                             batch_size=batch_size)\n",
    "\n",
    "    print(\"Input IDs:\", input_ids.shape)\n",
    "    print(\"Dataset size:\", len(dataset))\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def train(data_loader, epochs=3):\n",
    "    \"\"\"\n",
    "    Given the data_loader, it fine-tunes BERT for the specific task.\n",
    "    The BERT authors recommend between 2 and 4 training epochs.\n",
    "\n",
    "    Returns fine-tuned BERT model.\n",
    "    \"\"\"\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.cuda()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "    total_steps = len(data_loader) * epochs # total number of training steps is [number of batches] x [number of epochs]\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "    total_t0 = time.time() # keep track of time\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i+1, epochs))\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0 # reset the total loss for this epoch\n",
    "        model.train() # put the model into training mode\n",
    "\n",
    "        for batch in data_loader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad() # clears any previously calculated gradients before performing a backward pass\n",
    "\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 token_type_ids=None,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem\n",
    "            optimizer.step() # update parameters and take a step using the computed gradient\n",
    "            scheduler.step() # update the learning rate\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(data_loader)\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\\tAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\\tTraining epcoh took: {:}\".format(training_time))\n",
    "    print(\"\\n\\nTraining complete\\nTotal training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    \"\"\"\n",
    "    Given the fine-tuned model and data loader, it returns flat predictions, list of prob(fiction), and corresponding true-labels & IDs.\n",
    "\n",
    "    For predictions, we pick the label (0 or 1) with the higher score. The output for each batch are a 2-column ndarray (one column for \"0\"\n",
    "    and one column for \"1\"). Pick the label with the highest value and turn this in to a list of 0s and 1s.\n",
    "    \"\"\"\n",
    "    model.eval() # put model in evaluation mode\n",
    "\n",
    "    predictions, prob_fiction, true_labels, IDs = [], [], [], []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_input_ids, b_input_mask, b_labels, b_IDs = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                          attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = b_labels.to('cpu').numpy()\n",
    "        ids = b_IDs.to('cpu').numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(labels)\n",
    "        IDs.append(ids)\n",
    "\n",
    "\n",
    "    flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    probs = torch.nn.functional.softmax(torch.from_numpy(flat_predictions), dim=-1) # convert logits to probabilities\n",
    "    prob_fiction = probs[:,1] # because order is [0,1] and 1 is fiction\n",
    "    prob_fiction = prob_fiction.numpy()\n",
    "\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten() # pick the one with the highest value\n",
    "\n",
    "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "    flat_IDs = np.concatenate(IDs, axis=0)\n",
    "\n",
    "    return flat_predictions, prob_fiction, flat_true_labels, flat_IDs\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1554,
     "status": "ok",
     "timestamp": 1599673513065,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "mdsuwnv8t2-1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score #, precision_score, recall_score, accuracy_score, average_precision_score\n",
    "\n",
    "def run_bert():\n",
    "    \"\"\"\n",
    "    Runs the BERT model:\n",
    "    1) Prepares data loaders.\n",
    "    2) Fine-tunes the BERT model.\n",
    "    3) Returns the predictions on the test set.\n",
    "    \"\"\"\n",
    "    # DataLoader:\n",
    "    train_dataloader = prepare_dataloader(texts=X_train, labels=labels_train)\n",
    "    \n",
    "    print(\"Beginning training now..\")\n",
    "    # Train/fine-tune:\n",
    "    bert_model = train(train_dataloader)\n",
    "\n",
    "    # Predict on test set:\n",
    "    test_dataloader = prepare_dataloader(texts=X_test, labels=labels_test, IDs=testIDs_idx)\n",
    "    predictions, prob_fiction, true_labels, IDs_idx = predict(bert_model, test_dataloader)\n",
    "    print(\"Predictions: {}\\n\\nLabels:{}\\n\\nIDs_idx:{}\".format(predictions, true_labels, IDs_idx))\n",
    "    print(\"\\n\\n\\n\\nF1=\", f1_score(true_labels, predictions, pos_label=1))\n",
    "    write_predictions(IDs_idx, prob_fiction, predictions)\n",
    "\n",
    "\n",
    "\n",
    "def write_predictions(IDs_idx, prob_fiction, predictions):\n",
    "    # Save predictions:\n",
    "    print(\"Write predictions to:\", preds_path)\n",
    "\n",
    "    with open(preds_path, 'w') as f:\n",
    "        f.write('fname\\tprobability_fiction\\tprediction\\n')\n",
    "        for index, prob, pred in zip(IDs_idx, prob_fiction, predictions):\n",
    "            ID = test_IDs[int(index)]\n",
    "\n",
    "            if prob >= 0.5:\n",
    "                f.write(ID+'\\t'+str(prob)+'\\tfic\\n')\n",
    "                assert pred == 1\n",
    "            else:\n",
    "                f.write(ID+'\\t'+str(prob)+'\\tnon\\n')\n",
    "                assert pred == 0\n",
    "\n",
    "\n",
    "def labels_str_to_int(Y):\n",
    "    \"\"\"\n",
    "    Given the input labels, it converts them to integeres (fiction: 1 | non-fiction: 0)\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for l in Y:\n",
    "        if l == 'fic':\n",
    "            labels.append(1)\n",
    "        elif l == 'non':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            print(\"Error:\", l)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 326246,
     "status": "ok",
     "timestamp": 1599679316926,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "PBQUHkoZiNGW",
    "outputId": "02e4f23f-47a8-43c3-ac54-0ca489900440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write predictions to: /content/gdrive/My Drive/txtLAB-2020/bert-dialog/BERT_predictions_dial_0.tsv\n",
      "Running BERT for dialog: 0% and non-dialog: 100%\n",
      "Train Fiction fnames: 135 | Train Non-Fiction fnames: 100\n",
      "X_train: 400 | Y_train: 400 | Y Distribution: Counter({'fic': 200, 'non': 200}) | Dialog Dist: Counter({'ficNoDialog1': 100, 'ficNoDialog2': 100, 'non1': 100, 'non2': 100})\n",
      "Test Fiction fnames: 100 | Test Non-Fiction fnames: 100\n",
      "Test Set ---- X: 200 | Y: 200 | Distribution: Counter({'fic': 100, 'non': 100}) | Dialog dist in test: Counter({'non': 100, 'ficNoDialog': 50, 'ficWithDialog': 50}) | Test IDs: 200, preview: ['ficNoDialog____2012_Shapiro,BA_TheArtForger_MY.txt'\n",
      " 'ficNoDialog____2011_Aaronovitch,Ben_MidnightRiot_MY.txt'\n",
      " 'ficNoDialog____2013_Crouch,Blake_Wayward_MY.txt']\n",
      "testIDs indexes: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has input_ids, attention_masks, labels | Length: 400\n",
      "Input IDs: torch.Size([400, 512])\n",
      "Dataset size: 400\n",
      "Beginning training now..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n",
      "\tAverage training loss: 0.39\n",
      "\tTraining epcoh took: 0:00:47\n",
      "======== Epoch 2 / 3 ========\n",
      "\tAverage training loss: 0.11\n",
      "\tTraining epcoh took: 0:00:44\n",
      "======== Epoch 3 / 3 ========\n",
      "\tAverage training loss: 0.03\n",
      "\tTraining epcoh took: 0:00:45\n",
      "\n",
      "\n",
      "Training complete\n",
      "Total training took 0:02:15 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has input_ids, attention_masks, labels, and IDs\n",
      "Input IDs: torch.Size([200, 512])\n",
      "Dataset size: 200\n",
      "Predictions: [0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 1 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0]\n",
      "\n",
      "Labels:[1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1\n",
      " 1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
      " 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0]\n",
      "\n",
      "IDs_idx:[ 65.  80.  16.  50.  72.  53. 174. 127.  47. 147.  31.  32. 167. 101.\n",
      " 158.   7. 107.   4.  34.  69. 110.  39. 113. 153. 135. 130. 137.   8.\n",
      " 112. 126.  13. 115.   1.  10.  99. 123. 140. 197.  35.   3. 188. 160.\n",
      " 177.  52.  33. 100.  81. 161.  70. 155. 146.  58.  75. 142. 164.  74.\n",
      "  76. 132. 192. 148. 176.  59.  98.  90. 179.  64.  40.  45. 111. 168.\n",
      " 145.   0.  91.  27.  55.  66. 144.  11. 183.  38.  30.  51. 184.  62.\n",
      "  37.  78.  79.  77. 185.  12. 157.  18. 114. 199. 194.   5.   9. 156.\n",
      " 152. 182.  63.  48. 180. 175. 120. 149. 165. 122.  68. 172.  67.  83.\n",
      "   6. 189.  87.  54. 191. 136.  89.  21.  15. 133. 169.  85. 154.  46.\n",
      "  26.  92. 196. 117. 124.  28. 170. 121. 166.  49. 186.  14.  56. 104.\n",
      " 190. 105. 178.  84. 118. 129. 159. 103. 139. 141.  36.  82. 108.  43.\n",
      "  44. 119. 128.  25.  86. 171. 134. 143.  20.  95.   2.  57. 116. 162.\n",
      " 131.  42.  23.  22.  71.  88.  73. 173. 109. 151.  96.  61.  97.  24.\n",
      "  17. 106. 187. 181.  94.  41.  29. 138. 193. 125. 150.  19.  60. 195.\n",
      "  93. 198. 163. 102.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "F1= 0.6193548387096774\n",
      "Write predictions to: /content/gdrive/My Drive/txtLAB-2020/bert-dialog/BERT_predictions_dial_0.tsv\n"
     ]
    }
   ],
   "source": [
    "DIALOG = 0\n",
    "\n",
    "nondial = 100 - DIALOG\n",
    "preds_path = HOME_PATH + 'BERT_predictions_dial_'+str(DIALOG)+'.tsv'\n",
    "print(\"Write predictions to:\", preds_path)\n",
    "\n",
    "\n",
    "print(\"Running BERT for dialog: {}% and non-dialog: {}%\".format(DIALOG, nondial))\n",
    "X_train, Y_train, pct_quoted_fic, train_IDs = load_train_data(dial=DIALOG/100, no_dial=nondial/100)\n",
    "t = [i.split('____')[0] for i in train_IDs]\n",
    "print(\"X_train: {} | Y_train: {} | Y Distribution: {} | Dialog Dist: {}\".format(len(X_train), len(Y_train), Counter(Y_train), Counter(t)))\n",
    "assert len(X_train) == len(Y_train) == 400\n",
    "\n",
    "X_train = X_train.tolist(); Y_train = Y_train.tolist() # convert to list\n",
    "labels_train = labels_str_to_int(Y_train) # convert labels to integers\n",
    "\n",
    "# Test data:\n",
    "X_test, Y_test, pct_quoted_fic_test, test_IDs = load_test_data()\n",
    "t = [i.split('____')[0] for i in test_IDs]\n",
    "print(\"Test Set ---- X: {} | Y: {} | Distribution: {} | Dialog dist in test: {} | Test IDs: {}, preview: {}\".format(len(X_test), len(Y_test), Counter(Y_test), Counter(t), len(test_IDs), test_IDs[:3]))\n",
    "assert len(X_test) == len(Y_test) == 200\n",
    "\n",
    "X_test = X_test.tolist(); Y_test = Y_test.tolist(); test_IDs = test_IDs.tolist() # convert to list\n",
    "labels_test = labels_str_to_int(Y_test) # convert labels to integers\n",
    "testIDs_idx = np.linspace(0, len(test_IDs), len(test_IDs), False) # can't create a tensor of strings, so create a corresponding list of indexes; we use that to index into test_IDs\n",
    "print(\"testIDs indexes:\", len(testIDs_idx))\n",
    "\n",
    "run_bert()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSJepyNXKRz+7iCVCmkviw",
   "collapsed_sections": [],
   "name": "BERT-Dialog.ipynb",
   "provenance": [
    {
     "file_id": "1G8TFdEiUw8oj3ICCpa_rpYG-SgrUGniv",
     "timestamp": 1599662682603
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
