{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7235,
     "status": "ok",
     "timestamp": 1599756560676,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "VqOwCrGHfbW7",
    "outputId": "e049f8fe-9fc9-4a53-ac2c-c3912a060a57"
   },
   "source": [
    "### BERT for Gender experiments\n",
    "- We used Google Colaboratory for free GPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1653,
     "status": "ok",
     "timestamp": 1599756624714,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "4E-MqoeQppFW",
    "outputId": "df0238fa-807e-4976-c7c8-0cf16d08141a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NovelEnglish_Contemporary_Meta.csv',\n",
       " 'data',\n",
       " 'BERT_predictions_Male_0.tsv',\n",
       " 'BERT_predictions_Male_10.tsv',\n",
       " 'BERT_predictions_Male_20.tsv',\n",
       " 'BERT_predictions_Male_30.tsv',\n",
       " 'BERT_predictions_Male_40.tsv',\n",
       " 'BERT_predictions_Male_50.tsv']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME_PATH = '/content/gdrive/My Drive/txtLAB-2020/bert-gender/'\n",
    "import os\n",
    "os.listdir(HOME_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2382,
     "status": "ok",
     "timestamp": 1599756629487,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "NxriYi8Zr5DW",
    "outputId": "cfecd25e-d834-4449-8b84-0c7dedbecca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064 files in Gender Dictionary.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Loader for both train and test set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random; random.seed(41)\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "DATA_PATH = HOME_PATH + 'data/'\n",
    "df = pd.read_csv(HOME_PATH+'/NovelEnglish_Contemporary_Meta.csv')\n",
    "df = df.loc[df['Author_Gender'].isin(['F','M'])]\n",
    "GENDER_DICT = dict(zip(df.ID, df.Author_Gender))\n",
    "print(\"{} files in Gender Dictionary.\".format(len(GENDER_DICT)))\n",
    "\n",
    "\n",
    "def get_passage(fname, two_passages=False, three_passages=False, N=500):\n",
    "    \"\"\"\n",
    "    Returns a (continuous) passage of N words from the given txt/fname.\n",
    "    If 'two_passages' (or three passages) is set to True, returns two (or three) passages in a list.\n",
    "    \n",
    "    Note that the beginning and end (20/30%) of the txt is skipped.\n",
    "    \"\"\"\n",
    "    pct = 0.3\n",
    "    with open(fname, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    all_words = word_tokenize(text)\n",
    "    start = int(pct*len(all_words))\n",
    "    end = int(len(all_words) - pct*len(all_words))\n",
    "\n",
    "    # print(\"Total words: {} | Preview: {}\".format(len(all_words), all_words[10:12]))\n",
    "    # print(\"Start:\", start, \"| End:\", end)\n",
    "\n",
    "    if two_passages:\n",
    "        words1 = all_words[start:start+N]\n",
    "        words2 = all_words[start+N:start+N+N]\n",
    "#        print(\"Words1: {} | Words2: {}\".format(len(words1), len(words2)))\n",
    "        return [' '.join(words1), ' '.join(words2)]\n",
    "\n",
    "    elif three_passages:\n",
    "        words1 = all_words[start:start+N]\n",
    "        words2 = all_words[start+N:start+N+N]\n",
    "        words3 = all_words[start+N+N:start+N+N+N]\n",
    "        print(\"Words1: {} | Words2: {} | Words3: {}\".format(len(words1), len(words2), len(words3)))\n",
    "        return [' '.join(words1), ' '.join(words2), ' '.join(words3)]\n",
    "\n",
    "    else:\n",
    "        words = all_words[start:start+N]\n",
    "#        print(\"Words:\", len(words))\n",
    "        return ' '.join(words)\n",
    "\n",
    "\n",
    "######## Train Set ########\n",
    "def load_train_fnames():\n",
    "    \"\"\"\n",
    "    Returns a list of filenames to be used for train-data.\n",
    "    \"\"\"\n",
    "    fiction_fnames = [DATA_PATH+'Train/NovelEnglish_Mystery/'+fname for fname in os.listdir(DATA_PATH+'Train/NovelEnglish_Mystery/')]\n",
    "    non_fiction_fnames = [DATA_PATH+'Train/NonNovel_English_Contemporary_Mixed/'+fname for fname in os.listdir(DATA_PATH+'Train/NonNovel_English_Contemporary_Mixed/')]\n",
    "    print(\"Train Fiction fnames:\", len(fiction_fnames), \"| Train Non-Fiction fnames:\", len(non_fiction_fnames))\n",
    "    return fiction_fnames, non_fiction_fnames\n",
    "\n",
    "\n",
    "def load_train_data(male_pct, return_ids=False):\n",
    "    \"\"\"\n",
    "    Returns X and Y for training (400: 200 Fiction and 200 Non-Fiction) given the scenario. Also returns the IDs if flag is set to True.\n",
    "    male_pct (between 0 & 1) represents the ratio of fiction passages written by male authors. Female = 1 - male_pct\n",
    "    \n",
    "    Note: loads 2-3 500-word instances per 'fiction' volume; for scenarios that don't have 200 fiction fnames, loads two instances for a few fnames.\n",
    "    \"\"\"\n",
    "    fiction_fnames, non_fiction_fnames = load_train_fnames()\n",
    "    \n",
    "    MALE_FIC = male_pct*200\n",
    "    FEMALE_FIC = 200 - MALE_FIC\n",
    "    \n",
    "    print(\"Target for Male Fiction: {} | Target for Female Fiction: {}\".format(MALE_FIC, FEMALE_FIC))\n",
    "    \n",
    "    X = [] # list of training texts\n",
    "    Y = [] # corresponding list of training labels\n",
    "    IDs = [] # corresponding list of unique IDs\n",
    "    \n",
    "    male_fic_fnames, female_fic_fnames = [], []\n",
    "    for fname in fiction_fnames:\n",
    "        txt = fname.split('/')[-1]\n",
    "        if GENDER_DICT[txt] == 'M':\n",
    "            male_fic_fnames.append(fname)\n",
    "        elif GENDER_DICT[txt] == 'F':\n",
    "            female_fic_fnames.append(fname)\n",
    "        else:\n",
    "            print(\"Not possible!\")\n",
    "\n",
    "    N_three_fic_male = int(max(0, MALE_FIC-len(male_fic_fnames)*2))\n",
    "    N_three_fic_female = int(max(0, FEMALE_FIC-len(female_fic_fnames)*2))\n",
    "\n",
    "    male_counter, female_counter = 0, 0\n",
    "\n",
    "    print(\"\\nWe have {} male-fiction files and {} female-fiction files\".format(len(male_fic_fnames), len(female_fic_fnames)))\n",
    "    print(\"\\n\\nFor MALE: we need 2 passages from <= {} and 3 passages from {} files.\".format(len(male_fic_fnames)-N_three_fic_male, N_three_fic_male))\n",
    "    print(\"For FEMALE: we need 2 passages from <= {} and 3 passages from {} files.\\n\".format(len(female_fic_fnames)-N_three_fic_female, N_three_fic_female))\n",
    "\n",
    "    if N_three_fic_male != 0:\n",
    "        print(\"Get 3 passages from {} files: male\".format(N_three_fic_male))\n",
    "        for fname in male_fic_fnames[:N_three_fic_male]:\n",
    "            g = GENDER_DICT[fname.split('/')[-1]]\n",
    "            assert g == 'M'\n",
    "            X.extend(get_passage(fname, three_passages=True))\n",
    "            Y.extend([\"fic\", \"fic\", \"fic\"])\n",
    "            IDs.append(g+'_fic_1____'+txt)\n",
    "            IDs.append(g+'_fic_2____'+txt)\n",
    "            IDs.append(g+'_fic_3____'+txt)\n",
    "#            print(fname, \"has gender \", g)\n",
    "            male_counter += 3\n",
    "\n",
    "    if N_three_fic_female != 0:\n",
    "        print(\"Get 3 passages from {} files: female\".format(N_three_fic_female))\n",
    "        for fname in female_fic_fnames[:N_three_fic_female]:\n",
    "            g = GENDER_DICT[fname.split('/')[-1]]\n",
    "            assert g == 'F'\n",
    "            X.extend(get_passage(fname, three_passages=True))\n",
    "            Y.extend([\"fic\", \"fic\", \"fic\"])\n",
    "            IDs.append(g+'_fic_1____'+txt)\n",
    "            IDs.append(g+'_fic_2____'+txt)\n",
    "            IDs.append(g+'_fic_3____'+txt)\n",
    "#            print(fname, \"has gender \", g)\n",
    "            female_counter += 3\n",
    "\n",
    "    for fname in male_fic_fnames[N_three_fic_male:]:\n",
    "        if male_counter == MALE_FIC:\n",
    "            print(\"Reached male target. Break\", male_counter)\n",
    "            break\n",
    "        g = GENDER_DICT[fname.split('/')[-1]]\n",
    "        assert g == 'M'\n",
    "        X.extend(get_passage(fname, two_passages=True))\n",
    "        Y.extend([\"fic\", \"fic\"])\n",
    "        IDs.append(g+'_fic_1____'+txt)\n",
    "        IDs.append(g+'_fic_2____'+txt)\n",
    "#        print(fname, \"has gender \", g)\n",
    "        male_counter += 2\n",
    "\n",
    "\n",
    "    for fname in female_fic_fnames[N_three_fic_female:]:\n",
    "        if female_counter == FEMALE_FIC:\n",
    "            print(\"Reached female target. Break\", female_counter)\n",
    "            break\n",
    "        g = GENDER_DICT[fname.split('/')[-1]]\n",
    "        assert g == 'F'\n",
    "        X.extend(get_passage(fname, two_passages=True))\n",
    "        Y.extend([\"fic\", \"fic\"])\n",
    "        IDs.append(g+'_fic_1____'+txt)\n",
    "        IDs.append(g+'_fic_2____'+txt)\n",
    "#        print(fname, \"has gender \", g)\n",
    "        female_counter += 2\n",
    "\n",
    "\n",
    "    for fname in non_fiction_fnames: # need two passages per txt\n",
    "        X.extend(get_passage(fname, two_passages=True))\n",
    "        Y.append(\"non\")\n",
    "        Y.append(\"non\")\n",
    "        IDs.append('non1____'+fname.split('/')[-1])\n",
    "        IDs.append('non2____'+fname.split('/')[-1])\n",
    "\n",
    "    if return_ids:\n",
    "        return np.array(X), np.array(Y), np.array(IDs)\n",
    "    else:\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "######## Test Set ########\n",
    "def load_test_fnames():\n",
    "    \"\"\"\n",
    "    Returns a list of filenames to be used as test-data.\n",
    "    Test Data for all cases: 200 docs (100 \"Non\" & 100 fiction: 50 \"Male\" + 50 \"Female\")\n",
    "    There are 25 'M' files and 25 'F' files in fiction. Take two passages from each fiction and one from non-fiction.\n",
    "    \"\"\"\n",
    "    test_path = DATA_PATH + 'Test/'\n",
    "    fiction_fnames = [test_path+'NovelEnglish_Mystery/'+fname for fname in os.listdir(test_path+'NovelEnglish_Mystery/')]\n",
    "    non_fiction_fnames = [test_path+'NonNovel_English_Contemporary_Mixed/'+fname for fname in os.listdir(test_path+'NonNovel_English_Contemporary_Mixed/')]\n",
    "    print(\"Test Fiction fnames:\", len(fiction_fnames), \"| Test Non-Fiction fnames:\", len(non_fiction_fnames))\n",
    "    \n",
    "    return fiction_fnames, non_fiction_fnames\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Returns X and Y for test set. Also returns a corresponding list of IDs.\n",
    "    Take two passages from each fiction and one passage from non-fiction.\n",
    "    \"\"\"\n",
    "    fiction_fnames, non_fiction_fnames = load_test_fnames()\n",
    "\n",
    "    X = [] # list of texts\n",
    "    Y = [] # corresponding list of labels\n",
    "    IDs = [] # corresponding list of unique IDs\n",
    "\n",
    "    for fname in fiction_fnames:\n",
    "        txt = fname.split('/')[-1]\n",
    "        g = GENDER_DICT[txt]\n",
    "        X.extend(get_passage(fname, two_passages=True))\n",
    "        Y.extend([\"fic\", \"fic\"])\n",
    "        IDs.append(g+'_fic_1____'+txt)\n",
    "        IDs.append(g+'_fic_2____'+txt)\n",
    "        # print(txt, \"has gender \", g)\n",
    "    \n",
    "    for fname in non_fiction_fnames:\n",
    "        X.append(get_passage(fname))\n",
    "        Y.append(\"non\")\n",
    "        IDs.append('non____'+fname.split('/')[-1])\n",
    "\n",
    "    return np.array(X), np.array(Y), np.array(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7299,
     "status": "ok",
     "timestamp": 1599756635074,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "ETjSY0e_r5yK",
    "outputId": "e80f96c6-e659-484f-85c0-54e044927123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# Inspired from: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
    "import torch\n",
    "import random, time, datetime\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def prepare_dataloader(texts, labels, IDs=[], batch_size=8, max_length=512):\n",
    "    \"\"\"\n",
    "    Takes as input: texts, labels, and corresponding IDs (in case of test-data)\n",
    "    This function returns a DataLoader object.\n",
    "\n",
    "    For train_dataloader, labels are passed. For test_dataloader, both labels and IDs are passed.\n",
    "    BERT tokenizer is used to\n",
    "      (1) Tokenize the sentence.\n",
    "      (2) Prepend the `[CLS]` token to the start.\n",
    "      (3) Append the `[SEP]` token to the end.\n",
    "      (4) Map tokens to their IDs.\n",
    "      (5) Pad or truncate the sentence to `max_length`\n",
    "      (6) Create attention masks for [PAD] tokens.\n",
    "    Authors recommend a batch size of 16/32 for fine-tuning.\n",
    "    \"\"\"\n",
    "    input_ids = []; attention_masks = []\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    for sent in texts:\n",
    "        encoded_dict = tokenizer.encode_plus(sent, # sentence to encode\n",
    "                                             add_special_tokens=True, # add '[CLS]' and '[SEP]'\n",
    "                                             truncation=True,\n",
    "                                             max_length=512,\n",
    "                                             pad_to_max_length=True,\n",
    "                                             return_attention_mask=True, # construct attention masks\n",
    "                                             return_tensors='pt') # return pytorch tensorss\n",
    "\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask']) # simply differentiates padding from non-padding\n",
    "\n",
    "    # Convert to tensors:\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if IDs == []: # for training data\n",
    "        dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "        print(\"Dataset has input_ids, attention_masks, labels | Length:\", len(dataset))\n",
    "        \n",
    "    else: # for test data\n",
    "        IDs = torch.tensor(IDs)\n",
    "        print(\"Dataset has input_ids, attention_masks, labels, and IDs\")\n",
    "        dataset = TensorDataset(input_ids, attention_masks, labels, IDs)\n",
    "        assert len(dataset) == 200\n",
    "\n",
    "    data_loader = DataLoader(dataset,\n",
    "                             sampler=RandomSampler(dataset),\n",
    "                             batch_size=batch_size)\n",
    "\n",
    "    print(\"Input IDs:\", input_ids.shape)\n",
    "    print(\"Dataset size:\", len(dataset))\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def train(data_loader, epochs=3):\n",
    "    \"\"\"\n",
    "    Given the data_loader, it fine-tunes BERT for the specific task.\n",
    "    The BERT authors recommend between 2 and 4 training epochs.\n",
    "\n",
    "    Returns fine-tuned BERT model.\n",
    "    \"\"\"\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.cuda()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "    total_steps = len(data_loader) * epochs # total number of training steps is [number of batches] x [number of epochs]\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "    total_t0 = time.time() # keep track of time\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i+1, epochs))\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0 # reset the total loss for this epoch\n",
    "        model.train() # put the model into training mode\n",
    "\n",
    "        for batch in data_loader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad() # clears any previously calculated gradients before performing a backward pass\n",
    "\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 token_type_ids=None,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip the norm of the gradients to 1.0 to help prevent the \"exploding gradients\" problem\n",
    "            optimizer.step() # update parameters and take a step using the computed gradient\n",
    "            scheduler.step() # update the learning rate\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(data_loader)\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\\tAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\\tTraining epcoh took: {:}\".format(training_time))\n",
    "    print(\"\\n\\nTraining complete\\nTotal training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, data_loader):\n",
    "    \"\"\"\n",
    "    Given the fine-tuned model and data loader, it returns flat predictions, list of prob(fiction), and corresponding true-labels & IDs.\n",
    "\n",
    "    For predictions, we pick the label (0 or 1) with the higher score. The output for each batch are a 2-column ndarray (one column for \"0\"\n",
    "    and one column for \"1\"). Pick the label with the highest value and turn this in to a list of 0s and 1s.\n",
    "    \"\"\"\n",
    "    model.eval() # put model in evaluation mode\n",
    "\n",
    "    predictions, prob_fiction, true_labels, IDs = [], [], [], []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_input_ids, b_input_mask, b_labels, b_IDs = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "                          attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = b_labels.to('cpu').numpy()\n",
    "        ids = b_IDs.to('cpu').numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(labels)\n",
    "        IDs.append(ids)\n",
    "\n",
    "\n",
    "    flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    probs = torch.nn.functional.softmax(torch.from_numpy(flat_predictions), dim=-1) # convert logits to probabilities\n",
    "    prob_fiction = probs[:,1] # because order is [0,1] and 1 is fiction\n",
    "    prob_fiction = prob_fiction.numpy()\n",
    "\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten() # pick the one with the highest value\n",
    "\n",
    "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "    flat_IDs = np.concatenate(IDs, axis=0)\n",
    "\n",
    "    return flat_predictions, prob_fiction, flat_true_labels, flat_IDs\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5463,
     "status": "ok",
     "timestamp": 1599756635075,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "mdsuwnv8t2-1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score #, precision_score, recall_score, accuracy_score, average_precision_score\n",
    "\n",
    "def run_bert():\n",
    "    \"\"\"\n",
    "    Runs the BERT model:\n",
    "    1) Prepares data loaders.\n",
    "    2) Fine-tunes the BERT model.\n",
    "    3) Returns the predictions on the test set.\n",
    "    \"\"\"\n",
    "    # DataLoader:\n",
    "    train_dataloader = prepare_dataloader(texts=X_train, labels=labels_train)\n",
    "    \n",
    "    print(\"Beginning training now..\")\n",
    "    # Train/fine-tune:\n",
    "    bert_model = train(train_dataloader)\n",
    "\n",
    "    # Predict on test set:\n",
    "    test_dataloader = prepare_dataloader(texts=X_test, labels=labels_test, IDs=testIDs_idx)\n",
    "    predictions, prob_fiction, true_labels, IDs_idx = predict(bert_model, test_dataloader)\n",
    "    print(\"Predictions: {}\\n\\nLabels:{}\\n\\nIDs_idx:{}\".format(predictions, true_labels, IDs_idx))\n",
    "    print(\"\\n\\n\\n\\nF1=\", f1_score(true_labels, predictions, pos_label=1))\n",
    "    write_predictions(IDs_idx, prob_fiction, predictions)\n",
    "\n",
    "\n",
    "\n",
    "def write_predictions(IDs_idx, prob_fiction, predictions):\n",
    "    # Save predictions:\n",
    "    print(\"Write predictions to:\", preds_path)\n",
    "\n",
    "    with open(preds_path, 'w') as f:\n",
    "        f.write('fname\\tprobability_fiction\\tprediction\\n')\n",
    "        for index, prob, pred in zip(IDs_idx, prob_fiction, predictions):\n",
    "            ID = test_IDs[int(index)]\n",
    "\n",
    "            if prob >= 0.5:\n",
    "                f.write(ID+'\\t'+str(prob)+'\\tfic\\n')\n",
    "                assert pred == 1\n",
    "            else:\n",
    "                f.write(ID+'\\t'+str(prob)+'\\tnon\\n')\n",
    "                assert pred == 0\n",
    "\n",
    "\n",
    "def labels_str_to_int(Y):\n",
    "    \"\"\"\n",
    "    Given the input labels, it converts them to integeres (fiction: 1 | non-fiction: 0)\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for l in Y:\n",
    "        if l == 'fic':\n",
    "            labels.append(1)\n",
    "        elif l == 'non':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            print(\"Error:\", l)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 328384,
     "status": "ok",
     "timestamp": 1599759697855,
     "user": {
      "displayName": "Sunyam Bagga",
      "photoUrl": "",
      "userId": "14948313360107980438"
     },
     "user_tz": -330
    },
    "id": "PBQUHkoZiNGW",
    "outputId": "aa7197b4-6e87-401c-9ede-3e720fb9aa0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write predictions to: /content/gdrive/My Drive/txtLAB-2020/bert-gender/BERT_predictions_Male_100.tsv\n",
      "Running BERT for Male: 100% and Female: 0%\n",
      "Train Fiction fnames: 180 | Train Non-Fiction fnames: 100\n",
      "Target for Male Fiction: 200.0 | Target for Female Fiction: 0.0\n",
      "\n",
      "We have 85 male-fiction files and 95 female-fiction files\n",
      "\n",
      "\n",
      "For MALE: we need 2 passages from <= 55 and 3 passages from 30 files.\n",
      "For FEMALE: we need 2 passages from <= 95 and 3 passages from 0 files.\n",
      "\n",
      "Get 3 passages from 30 files: male\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Words1: 500 | Words2: 500 | Words3: 500\n",
      "Reached female target. Break 0\n",
      "X_train: 400 | Y_train: 400 | Y Distribution: Counter({'fic': 200, 'non': 200}) | Gender Dist: Counter({'M_fic': 200, 'non1_': 100, 'non2_': 100})\n",
      "Test Fiction fnames: 50 | Test Non-Fiction fnames: 100\n",
      "Test Set ---- X: 200 | Y: 200 | Distribution: Counter({'fic': 100, 'non': 100}) | Gender dist in test: Counter({'non__': 100, 'F_fic': 50, 'M_fic': 50}) | Test IDs: 200, preview: ['F_fic_1____2012_Shapiro,BA_TheArtForger_MY.txt'\n",
      " 'F_fic_2____2012_Shapiro,BA_TheArtForger_MY.txt'\n",
      " 'M_fic_1____2013_Crouch,Blake_Wayward_MY.txt']\n",
      "testIDs indexes: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has input_ids, attention_masks, labels | Length: 400\n",
      "Input IDs: torch.Size([400, 512])\n",
      "Dataset size: 400\n",
      "Beginning training now..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n",
      "\tAverage training loss: 0.50\n",
      "\tTraining epcoh took: 0:00:23\n",
      "======== Epoch 2 / 3 ========\n",
      "\tAverage training loss: 0.17\n",
      "\tTraining epcoh took: 0:00:23\n",
      "======== Epoch 3 / 3 ========\n",
      "\tAverage training loss: 0.10\n",
      "\tTraining epcoh took: 0:00:22\n",
      "\n",
      "\n",
      "Training complete\n",
      "Total training took 0:01:08 (h:mm:ss)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has input_ids, attention_masks, labels, and IDs\n",
      "Input IDs: torch.Size([200, 512])\n",
      "Dataset size: 200\n",
      "Predictions: [1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1\n",
      " 0 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1]\n",
      "\n",
      "Labels:[1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 1 1\n",
      " 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 1 0\n",
      " 0 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0]\n",
      "\n",
      "IDs_idx:[ 65. 139.  84. 152.  89.  50. 177.  10. 146.   1. 156.  60. 167.  61.\n",
      "  92.  93. 107. 119.  82. 163. 176. 187.  37. 172.  30. 115.  48.  12.\n",
      " 127.  38. 128. 157. 188.  42. 145.  96.  76. 151.  75.  94. 191. 144.\n",
      "  88.   5. 162. 194. 138.  35.  21.   0.  51. 190. 102.  15. 189. 169.\n",
      "   7. 133.  91. 161.  17.  40.  69. 117. 154.  28.  77.  14. 105.  36.\n",
      " 104.  31.  44. 174. 135.  90.  95. 159. 153. 124.  99. 137.  98.  49.\n",
      " 183.  25.  58. 106.  43. 166. 116. 129.  19.  46.  53. 103.  80. 142.\n",
      "  68.  20.  33.  85.  78. 122.  57. 168.  59.  71.   4.  63.  32.  22.\n",
      " 126. 131. 114. 118.  70. 113. 141.  79.  23. 136.   3. 112. 197. 111.\n",
      "   9.  56.  97.  26.  41. 178.  55. 155. 196. 164. 150. 179.   6. 186.\n",
      "  54.  27.  18. 184. 175. 120. 134.  86.  74. 125. 181.  11. 198. 109.\n",
      " 160. 149.  47.  87. 170.  83.  52. 173. 147. 100. 180.  72. 165. 192.\n",
      " 193. 108.  45.  66.  34. 130. 195. 140.  81.  24. 132.  16. 199.  67.\n",
      " 123. 110.  13. 121. 158. 171. 101.   2.   8.  73.  29.  64.  62.  39.\n",
      " 185. 182. 143. 148.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "F1= 0.9607843137254902\n",
      "Write predictions to: /content/gdrive/My Drive/txtLAB-2020/bert-gender/BERT_predictions_Male_100.tsv\n"
     ]
    }
   ],
   "source": [
    "MALE = 100\n",
    "\n",
    "female = 100 - MALE\n",
    "preds_path = HOME_PATH + 'BERT_predictions_Male_'+str(MALE)+'.tsv'\n",
    "print(\"Write predictions to:\", preds_path)\n",
    "\n",
    "\n",
    "print(\"Running BERT for Male: {}% and Female: {}%\".format(MALE, female))\n",
    "X_train, Y_train, train_IDs = load_train_data(male_pct=int(MALE)/100, return_ids=True)\n",
    "t = [i[:5] for i in train_IDs]\n",
    "print(\"X_train: {} | Y_train: {} | Y Distribution: {} | Gender Dist: {}\".format(len(X_train), len(Y_train), Counter(Y_train), Counter(t)))\n",
    "assert len(X_train) == len(Y_train) == 400\n",
    "\n",
    "X_train = X_train.tolist(); Y_train = Y_train.tolist() # convert to list\n",
    "labels_train = labels_str_to_int(Y_train) # convert labels to integers\n",
    "\n",
    "# Test data:\n",
    "X_test, Y_test, test_IDs = load_test_data()\n",
    "t = [i[:5] for i in test_IDs]\n",
    "print(\"Test Set ---- X: {} | Y: {} | Distribution: {} | Gender dist in test: {} | Test IDs: {}, preview: {}\".format(len(X_test), len(Y_test), Counter(Y_test), Counter(t), len(test_IDs), test_IDs[:3]))\n",
    "assert len(X_test) == len(Y_test) == 200\n",
    "\n",
    "X_test = X_test.tolist(); Y_test = Y_test.tolist(); test_IDs = test_IDs.tolist() # convert to list\n",
    "labels_test = labels_str_to_int(Y_test) # convert labels to integers\n",
    "testIDs_idx = np.linspace(0, len(test_IDs), len(test_IDs), False) # can't create a tensor of strings, so create a corresponding list of indexes; we use that to index into test_IDs\n",
    "print(\"testIDs indexes:\", len(testIDs_idx))\n",
    "\n",
    "run_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xLd6uQ93soG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPvcsWTut29JZl1V06F5y43",
   "collapsed_sections": [],
   "name": "BERT-Gender.ipynb",
   "provenance": [
    {
     "file_id": "1oOeHaKqUkNURG6X9EpdVoTOFyl5Sknrm",
     "timestamp": 1599743633659
    },
    {
     "file_id": "1G8TFdEiUw8oj3ICCpa_rpYG-SgrUGniv",
     "timestamp": 1599662682603
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
